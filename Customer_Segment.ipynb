{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Customer-Segment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sauravsingla/General/blob/master/Customer_Segment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goqQAI_cPnlm",
        "outputId": "15d272ac-20be-41ee-dbeb-145a02d30580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEwe4XbsPvS2"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvgJSrHCP03V"
      },
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "  random_image_cpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n",
        "  net_cpu = tf.reduce_sum(net_cpu)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
        "  net_gpu = tf.reduce_sum(net_gpu)\n",
        "\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "# Test execution once to detect errors early.\n",
        "try:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "except tf.errors.InvalidArgumentError:\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise\n",
        "\n",
        "def cpu():\n",
        "  sess.run(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  sess.run(net_gpu)\n",
        "\n",
        "# Runs the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFPtApP7QkY2"
      },
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TfgddbDP9_m"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC-LdcOTQK9e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime, nltk, warnings\n",
        "import matplotlib.cm as cm\n",
        "import itertools\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from sklearn import preprocessing, model_selection, metrics, feature_selection\n",
        "from sklearn.model_selection import GridSearchCV, learning_curve\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import neighbors, linear_model, svm, tree, ensemble\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from IPython.display import display, HTML\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode,iplot\n",
        "init_notebook_mode(connected=True)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
        "plt.style.use('fivethirtyeight')\n",
        "mpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BSYSMhaRwtE"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKP8aryDUpeM"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDRYiaE_U6Vr"
      },
      "source": [
        "# Let's make sure the kaggle.json file is present.\n",
        "!ls -lha kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VCOWzVFVElc"
      },
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZHXAkBKVMJN"
      },
      "source": [
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7WygvDfVUW8"
      },
      "source": [
        "# List available datasets.\n",
        "!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4xsJS7PW4uT"
      },
      "source": [
        "!mkdir -p data\n",
        "!kaggle competitions download -c miia4406-movie-genre-classification -f dataTraining.csv -p data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOb1LoX6XAZU"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5ZiHPvqYJ1N"
      },
      "source": [
        "!wget kaggle.com/fabiendaniel/customer-segmentation/data/data.csv.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJEVCOwXZSxq"
      },
      "source": [
        "!unzip data.csv.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65jrnLaMZn-j"
      },
      "source": [
        "df_initial = pd.read_csv('data.csv',encoding=\"ISO-8859-1\",\n",
        "                         dtype={'CustomerID': str,'InvoiceID': str})\n",
        "print('Dataframe dimensions:', df_initial.shape)\n",
        "#______\n",
        "df_initial['InvoiceDate'] = pd.to_datetime(df_initial['InvoiceDate'])\n",
        "#____________________________________________________________\n",
        "# gives some infos on columns types and numer of null values\n",
        "tab_info=pd.DataFrame(df_initial.dtypes).T.rename(index={0:'column type'})\n",
        "tab_info=tab_info.append(pd.DataFrame(df_initial.isnull().sum()).T.rename(index={0:'null values (nb)'}))\n",
        "tab_info=tab_info.append(pd.DataFrame(df_initial.isnull().sum()/df_initial.shape[0]*100).T.\n",
        "                         rename(index={0:'null values (%)'}))\n",
        "display(tab_info)\n",
        "#__________________\n",
        "# show first lines\n",
        "display(df_initial[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3Y-XfGeZ_OD"
      },
      "source": [
        "df_initial.dropna(axis = 0, subset = ['CustomerID'], inplace = True)\n",
        "print('Dataframe dimensions:', df_initial.shape)\n",
        "#____________________________________________________________\n",
        "# gives some infos on columns types and numer of null values\n",
        "tab_info=pd.DataFrame(df_initial.dtypes).T.rename(index={0:'column type'})\n",
        "tab_info=tab_info.append(pd.DataFrame(df_initial.isnull().sum()).T.rename(index={0:'null values (nb)'}))\n",
        "tab_info=tab_info.append(pd.DataFrame(df_initial.isnull().sum()/df_initial.shape[0]*100).T.\n",
        "                         rename(index={0:'null values (%)'}))\n",
        "display(tab_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chTWnkxPaDY7",
        "outputId": "96656860-c939-445f-a426-e6e26da35b33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Entrées dupliquées: {}'.format(df_initial.duplicated().sum()))\n",
        "df_initial.drop_duplicates(inplace = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entrées dupliquées: 5225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpc2mmIeaT77"
      },
      "source": [
        "temp = df_initial[['CustomerID', 'InvoiceNo', 'Country']].groupby(['CustomerID', 'InvoiceNo', 'Country']).count()\n",
        "temp = temp.reset_index(drop = False)\n",
        "countries = temp['Country'].value_counts()\n",
        "print('Nb. de pays dans le dataframe: {}'.format(len(countries)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhL8IUn7ad5j"
      },
      "source": [
        "data = dict(type='choropleth',\n",
        "locations = countries.index,\n",
        "locationmode = 'country names', z = countries,\n",
        "text = countries.index, colorbar = {'title':'Order nb.'},\n",
        "colorscale=[[0, 'rgb(224,255,255)'],\n",
        "            [0.01, 'rgb(166,206,227)'], [0.02, 'rgb(31,120,180)'],\n",
        "            [0.03, 'rgb(178,223,138)'], [0.05, 'rgb(51,160,44)'],\n",
        "            [0.10, 'rgb(251,154,153)'], [0.20, 'rgb(255,255,0)'],\n",
        "            [1, 'rgb(227,26,28)']],    \n",
        "reversescale = False)\n",
        "#_______________________\n",
        "layout = dict(title='Number of orders per country',\n",
        "geo = dict(showframe = True, projection={'type':'Mercator'}))\n",
        "#______________\n",
        "choromap = go.Figure(data = [data], layout = layout)\n",
        "iplot(choromap, validate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz4owuU4aoJG"
      },
      "source": [
        "pd.DataFrame([{'products': len(df_initial['StockCode'].value_counts()),    \n",
        "               'transactions': len(df_initial['InvoiceNo'].value_counts()),\n",
        "               'customers': len(df_initial['CustomerID'].value_counts()),  \n",
        "              }], columns = ['products', 'transactions', 'customers'], index = ['quantity'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB3frCsVauPv"
      },
      "source": [
        "temp = df_initial.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['InvoiceDate'].count()\n",
        "nb_products_per_basket = temp.rename(columns = {'InvoiceDate':'Number of products'})\n",
        "nb_products_per_basket[:10].sort_values('CustomerID')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aJSYS9ea5hi"
      },
      "source": [
        "nb_products_per_basket['order_canceled'] = nb_products_per_basket['InvoiceNo'].apply(lambda x:int('C' in x))\n",
        "display(nb_products_per_basket[:5])\n",
        "#______________________________________________________________________________________________\n",
        "n1 = nb_products_per_basket['order_canceled'].sum()\n",
        "n2 = nb_products_per_basket.shape[0]\n",
        "print('Number of orders canceled: {}/{} ({:.2f}%) '.format(n1, n2, n1/n2*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_qe0d-ga-tb"
      },
      "source": [
        "display(df_initial.sort_values('CustomerID')[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2ns3kvfbQz7"
      },
      "source": [
        "df_check = df_initial[df_initial['Quantity'] < 0][['CustomerID','Quantity',\n",
        "                                                   'StockCode','Description','UnitPrice']]\n",
        "for index, col in  df_check.iterrows():\n",
        "    if df_initial[(df_initial['CustomerID'] == col[0]) & (df_initial['Quantity'] == -col[1]) \n",
        "                & (df_initial['Description'] == col[2])].shape[0] == 0: \n",
        "        print(df_check.loc[index])\n",
        "        print(15*'-'+'>'+' HYPOTHESIS NOT FULFILLED')\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGP5IBFubYQs"
      },
      "source": [
        "df_check = df_initial[(df_initial['Quantity'] < 0) & (df_initial['Description'] != 'Discount')][\n",
        "                                 ['CustomerID','Quantity','StockCode',\n",
        "                                  'Description','UnitPrice']]\n",
        "\n",
        "for index, col in  df_check.iterrows():\n",
        "    if df_initial[(df_initial['CustomerID'] == col[0]) & (df_initial['Quantity'] == -col[1]) \n",
        "                & (df_initial['Description'] == col[2])].shape[0] == 0: \n",
        "        print(index, df_check.loc[index])\n",
        "        print(15*'-'+'>'+' HYPOTHESIS NOT FULFILLED')\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiJIaUwobhwS"
      },
      "source": [
        "df_cleaned = df_initial.copy(deep = True)\n",
        "df_cleaned['QuantityCanceled'] = 0\n",
        "\n",
        "entry_to_remove = [] ; doubtfull_entry = []\n",
        "\n",
        "for index, col in  df_initial.iterrows():\n",
        "    if (col['Quantity'] > 0) or col['Description'] == 'Discount': continue        \n",
        "    df_test = df_initial[(df_initial['CustomerID'] == col['CustomerID']) &\n",
        "                         (df_initial['StockCode']  == col['StockCode']) & \n",
        "                         (df_initial['InvoiceDate'] < col['InvoiceDate']) & \n",
        "                         (df_initial['Quantity']   > 0)].copy()\n",
        "    #_________________________________\n",
        "    # Cancelation WITHOUT counterpart\n",
        "    if (df_test.shape[0] == 0): \n",
        "        doubtfull_entry.append(index)\n",
        "    #________________________________\n",
        "    # Cancelation WITH a counterpart\n",
        "    elif (df_test.shape[0] == 1): \n",
        "        index_order = df_test.index[0]\n",
        "        df_cleaned.loc[index_order, 'QuantityCanceled'] = -col['Quantity']\n",
        "        entry_to_remove.append(index)        \n",
        "    #______________________________________________________________\n",
        "    # Various counterparts exist in orders: we delete the last one\n",
        "    elif (df_test.shape[0] > 1): \n",
        "        df_test.sort_index(axis=0 ,ascending=False, inplace = True)        \n",
        "        for ind, val in df_test.iterrows():\n",
        "            if val['Quantity'] < -col['Quantity']: continue\n",
        "            df_cleaned.loc[ind, 'QuantityCanceled'] = -col['Quantity']\n",
        "            entry_to_remove.append(index) \n",
        "            break          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyyz9w5cbr8t",
        "outputId": "ceee3217-3f03-4ead-e3d5-7aa1af71d30b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"entry_to_remove: {}\".format(len(entry_to_remove)))\n",
        "print(\"doubtfull_entry: {}\".format(len(doubtfull_entry)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "entry_to_remove: 7521\n",
            "doubtfull_entry: 1226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUmgMyGAbyiM",
        "outputId": "2a273e85-c40c-4df9-cd61-37bb3ae292b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "df_cleaned.drop(entry_to_remove, axis = 0, inplace = True)\n",
        "df_cleaned.drop(doubtfull_entry, axis = 0, inplace = True)\n",
        "remaining_entries = df_cleaned[(df_cleaned['Quantity'] < 0) & (df_cleaned['StockCode'] != 'D')]\n",
        "print(\"nb of entries to delete: {}\".format(remaining_entries.shape[0]))\n",
        "remaining_entries[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb of entries to delete: 48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>InvoiceNo</th>\n",
              "      <th>StockCode</th>\n",
              "      <th>Description</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>InvoiceDate</th>\n",
              "      <th>UnitPrice</th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Country</th>\n",
              "      <th>QuantityCanceled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>77598</th>\n",
              "      <td>C542742</td>\n",
              "      <td>84535B</td>\n",
              "      <td>FAIRY CAKES NOTEBOOK A6 SIZE</td>\n",
              "      <td>-94</td>\n",
              "      <td>2011-01-31 16:26:00</td>\n",
              "      <td>0.65</td>\n",
              "      <td>15358</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90444</th>\n",
              "      <td>C544038</td>\n",
              "      <td>22784</td>\n",
              "      <td>LANTERN CREAM GAZEBO</td>\n",
              "      <td>-4</td>\n",
              "      <td>2011-02-15 11:32:00</td>\n",
              "      <td>4.95</td>\n",
              "      <td>14659</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111968</th>\n",
              "      <td>C545852</td>\n",
              "      <td>22464</td>\n",
              "      <td>HANGING METAL HEART LANTERN</td>\n",
              "      <td>-5</td>\n",
              "      <td>2011-03-07 13:49:00</td>\n",
              "      <td>1.65</td>\n",
              "      <td>14048</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116064</th>\n",
              "      <td>C546191</td>\n",
              "      <td>47566B</td>\n",
              "      <td>TEA TIME PARTY BUNTING</td>\n",
              "      <td>-35</td>\n",
              "      <td>2011-03-10 10:57:00</td>\n",
              "      <td>0.70</td>\n",
              "      <td>16422</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132642</th>\n",
              "      <td>C547675</td>\n",
              "      <td>22263</td>\n",
              "      <td>FELT EGG COSY LADYBIRD</td>\n",
              "      <td>-49</td>\n",
              "      <td>2011-03-24 14:07:00</td>\n",
              "      <td>0.66</td>\n",
              "      <td>17754</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       InvoiceNo StockCode                   Description  Quantity  \\\n",
              "77598    C542742    84535B  FAIRY CAKES NOTEBOOK A6 SIZE       -94   \n",
              "90444    C544038     22784         LANTERN CREAM GAZEBO         -4   \n",
              "111968   C545852     22464   HANGING METAL HEART LANTERN        -5   \n",
              "116064   C546191    47566B        TEA TIME PARTY BUNTING       -35   \n",
              "132642   C547675     22263       FELT EGG COSY LADYBIRD        -49   \n",
              "\n",
              "               InvoiceDate  UnitPrice CustomerID         Country  \\\n",
              "77598  2011-01-31 16:26:00       0.65      15358  United Kingdom   \n",
              "90444  2011-02-15 11:32:00       4.95      14659  United Kingdom   \n",
              "111968 2011-03-07 13:49:00       1.65      14048  United Kingdom   \n",
              "116064 2011-03-10 10:57:00       0.70      16422  United Kingdom   \n",
              "132642 2011-03-24 14:07:00       0.66      17754  United Kingdom   \n",
              "\n",
              "        QuantityCanceled  \n",
              "77598                  0  \n",
              "90444                  0  \n",
              "111968                 0  \n",
              "116064                 0  \n",
              "132642                 0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptys9X4Vb7vD",
        "outputId": "7357388f-8b9b-465a-9ba0-b4a9de430cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "df_cleaned[(df_cleaned['CustomerID'] == 14048) & (df_cleaned['StockCode'] == '22464')]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>InvoiceNo</th>\n",
              "      <th>StockCode</th>\n",
              "      <th>Description</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>InvoiceDate</th>\n",
              "      <th>UnitPrice</th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Country</th>\n",
              "      <th>QuantityCanceled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [InvoiceNo, StockCode, Description, Quantity, InvoiceDate, UnitPrice, CustomerID, Country, QuantityCanceled]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vZgK9hQcCg0",
        "outputId": "0ab96249-667c-4ec1-e28a-f3c0fa974b1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "list_special_codes = df_cleaned[df_cleaned['StockCode'].str.contains('^[a-zA-Z]+', regex=True)]['StockCode'].unique()\n",
        "list_special_codes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['POST', 'D', 'C2', 'M', 'BANK CHARGES', 'PADS', 'DOT'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qimUW5K9cIMz",
        "outputId": "9b13c7f5-d9a2-4c18-a46b-a8c1140a4be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "for code in list_special_codes:\n",
        "    print(\"{:<15} -> {:<30}\".format(code, df_cleaned[df_cleaned['StockCode'] == code]['Description'].unique()[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "POST            -> POSTAGE                       \n",
            "D               -> Discount                      \n",
            "C2              -> CARRIAGE                      \n",
            "M               -> Manual                        \n",
            "BANK CHARGES    -> Bank Charges                  \n",
            "PADS            -> PADS TO MATCH ALL CUSHIONS    \n",
            "DOT             -> DOTCOM POSTAGE                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0HvwCGmcOvi"
      },
      "source": [
        "df_cleaned['TotalPrice'] = df_cleaned['UnitPrice'] * (df_cleaned['Quantity'] - df_cleaned['QuantityCanceled'])\n",
        "df_cleaned.sort_values('CustomerID')[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmomq7wDchHL",
        "outputId": "8c7d22e9-d024-45b7-c8c7-637870cf963e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "#___________________________________________\n",
        "# somme des achats / utilisateur & commande\n",
        "temp = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['TotalPrice'].sum()\n",
        "basket_price = temp.rename(columns = {'TotalPrice':'Basket Price'})\n",
        "#_____________________\n",
        "# date de la commande\n",
        "df_cleaned['InvoiceDate_int'] = df_cleaned['InvoiceDate'].astype('int64')\n",
        "temp = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['InvoiceDate_int'].mean()\n",
        "df_cleaned.drop('InvoiceDate_int', axis = 1, inplace = True)\n",
        "basket_price.loc[:, 'InvoiceDate'] = pd.to_datetime(temp['InvoiceDate_int'])\n",
        "#______________________________________\n",
        "# selection des entrées significatives:\n",
        "basket_price = basket_price[basket_price['Basket Price'] > 0]\n",
        "basket_price.sort_values('CustomerID')[:6]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>InvoiceNo</th>\n",
              "      <th>Basket Price</th>\n",
              "      <th>InvoiceDate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12347</td>\n",
              "      <td>537626</td>\n",
              "      <td>711.79</td>\n",
              "      <td>2010-12-07 14:57:00.000001024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12347</td>\n",
              "      <td>542237</td>\n",
              "      <td>475.39</td>\n",
              "      <td>2011-01-26 14:29:59.999999744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12347</td>\n",
              "      <td>549222</td>\n",
              "      <td>636.25</td>\n",
              "      <td>2011-04-07 10:42:59.999999232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12347</td>\n",
              "      <td>556201</td>\n",
              "      <td>382.52</td>\n",
              "      <td>2011-06-09 13:01:00.000000256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12347</td>\n",
              "      <td>562032</td>\n",
              "      <td>584.91</td>\n",
              "      <td>2011-08-02 08:48:00.000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>12347</td>\n",
              "      <td>573511</td>\n",
              "      <td>1294.32</td>\n",
              "      <td>2011-10-31 12:25:00.000001280</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  CustomerID InvoiceNo  Basket Price                   InvoiceDate\n",
              "1      12347    537626        711.79 2010-12-07 14:57:00.000001024\n",
              "2      12347    542237        475.39 2011-01-26 14:29:59.999999744\n",
              "3      12347    549222        636.25 2011-04-07 10:42:59.999999232\n",
              "4      12347    556201        382.52 2011-06-09 13:01:00.000000256\n",
              "5      12347    562032        584.91 2011-08-02 08:48:00.000000000\n",
              "6      12347    573511       1294.32 2011-10-31 12:25:00.000001280"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD_rPw2scpjd"
      },
      "source": [
        "#____________________\n",
        "# Décompte des achats\n",
        "price_range = [0, 50, 100, 200, 500, 1000, 5000, 50000]\n",
        "count_price = []\n",
        "for i, price in enumerate(price_range):\n",
        "    if i == 0: continue\n",
        "    val = basket_price[(basket_price['Basket Price'] < price) &\n",
        "                       (basket_price['Basket Price'] > price_range[i-1])]['Basket Price'].count()\n",
        "    count_price.append(val)\n",
        "#____________________________________________\n",
        "# Représentation du nombre d'achats / montant        \n",
        "plt.rc('font', weight='bold')\n",
        "f, ax = plt.subplots(figsize=(11, 6))\n",
        "colors = ['yellowgreen', 'gold', 'wheat', 'c', 'violet', 'royalblue','firebrick']\n",
        "labels = [ '{}<.<{}'.format(price_range[i-1], s) for i,s in enumerate(price_range) if i != 0]\n",
        "sizes  = count_price\n",
        "explode = [0.0 if sizes[i] < 100 else 0.0 for i in range(len(sizes))]\n",
        "ax.pie(sizes, explode = explode, labels=labels, colors = colors,\n",
        "       autopct = lambda x:'{:1.0f}%'.format(x) if x > 1 else '',\n",
        "       shadow = False, startangle=0)\n",
        "ax.axis('equal')\n",
        "f.text(0.5, 1.01, \"Répartition des montants des commandes\", ha='center', fontsize = 18);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHiQpnwxc0Eg"
      },
      "source": [
        "is_noun = lambda pos: pos[:2] == 'NN'\n",
        "\n",
        "def keywords_inventory(dataframe, colonne = 'Description'):\n",
        "    stemmer = nltk.stem.SnowballStemmer(\"english\")\n",
        "    keywords_roots  = dict()  # collect the words / root\n",
        "    keywords_select = dict()  # association: root <-> keyword\n",
        "    category_keys   = []\n",
        "    count_keywords  = dict()\n",
        "    icount = 0\n",
        "    for s in dataframe[colonne]:\n",
        "        if pd.isnull(s): continue\n",
        "        lines = s.lower()\n",
        "        tokenized = nltk.word_tokenize(lines)\n",
        "        nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos)] \n",
        "        \n",
        "        for t in nouns:\n",
        "            t = t.lower() ; racine = stemmer.stem(t)\n",
        "            if racine in keywords_roots:                \n",
        "                keywords_roots[racine].add(t)\n",
        "                count_keywords[racine] += 1                \n",
        "            else:\n",
        "                keywords_roots[racine] = {t}\n",
        "                count_keywords[racine] = 1\n",
        "    for s in keywords_roots.keys():\n",
        "        if len(keywords_roots[s]) > 1:  \n",
        "            min_length = 1000\n",
        "            for k in keywords_roots[s]:\n",
        "                if len(k) < min_length:\n",
        "                    clef = k ; min_length = len(k)            \n",
        "            category_keys.append(clef)\n",
        "            keywords_select[s] = clef\n",
        "        else:\n",
        "            category_keys.append(list(keywords_roots[s])[0])\n",
        "            keywords_select[s] = list(keywords_roots[s])[0]\n",
        "                   \n",
        "    print(\"Nb of keywords in variable '{}': {}\".format(colonne,len(category_keys)))\n",
        "    return category_keys, keywords_roots, keywords_select, count_keywords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE_iRxgHdNvO"
      },
      "source": [
        "df_produits = pd.DataFrame(df_initial['Description'].unique()).rename(columns = {0:'Description'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfZbSA0RdYi1"
      },
      "source": [
        "Keywords, keywords_roots, keywords_select, count_keywords = keywords_inventory(df_produits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oL3ZfvpdamN"
      },
      "source": [
        "list_products = []\n",
        "for k,v in count_keywords.items():\n",
        "    list_products.append([keywords_select[k],v])\n",
        "list_products.sort(key = lambda x:x[1], reverse = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QRoZDQwdgYZ"
      },
      "source": [
        "liste = sorted(list_products, key = lambda x:x[1], reverse = True)\n",
        "#_______________________________\n",
        "plt.rc('font', weight='normal')\n",
        "fig, ax = plt.subplots(figsize=(7, 25))\n",
        "y_axis = [i[1] for i in liste[:125]]\n",
        "x_axis = [k for k,i in enumerate(liste[:125])]\n",
        "x_label = [i[0] for i in liste[:125]]\n",
        "plt.xticks(fontsize = 15)\n",
        "plt.yticks(fontsize = 13)\n",
        "plt.yticks(x_axis, x_label)\n",
        "plt.xlabel(\"Nb. of occurences\", fontsize = 18, labelpad = 10)\n",
        "ax.barh(x_axis, y_axis, align = 'center')\n",
        "ax = plt.gca()\n",
        "ax.invert_yaxis()\n",
        "#_______________________________________________________________________________________\n",
        "plt.title(\"Words occurence\",bbox={'facecolor':'k', 'pad':5}, color='w',fontsize = 25)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKrqXLmKdh0b"
      },
      "source": [
        "list_products = []\n",
        "for k,v in count_keywords.items():\n",
        "    word = keywords_select[k]\n",
        "    if word in ['pink', 'blue', 'tag', 'green', 'orange']: continue\n",
        "    if len(word) < 3 or v < 13: continue\n",
        "    if ('+' in word) or ('/' in word): continue\n",
        "    list_products.append([word, v])\n",
        "#______________________________________________________    \n",
        "list_products.sort(key = lambda x:x[1], reverse = True)\n",
        "print('mots conservés:', len(list_products))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQc9LRn4dmx-"
      },
      "source": [
        "liste_produits = df_cleaned['Description'].unique()\n",
        "X = pd.DataFrame()\n",
        "for key, occurence in list_products:\n",
        "    X.loc[:, key] = list(map(lambda x:int(key.upper() in x), liste_produits))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUiKTjQHdriR"
      },
      "source": [
        "threshold = [0, 1, 2, 3, 5, 10]\n",
        "label_col = []\n",
        "for i in range(len(threshold)):\n",
        "    if i == len(threshold)-1:\n",
        "        col = '.>{}'.format(threshold[i])\n",
        "    else:\n",
        "        col = '{}<.<{}'.format(threshold[i],threshold[i+1])\n",
        "    label_col.append(col)\n",
        "    X.loc[:, col] = 0\n",
        "\n",
        "for i, prod in enumerate(liste_produits):\n",
        "    prix = df_cleaned[ df_cleaned['Description'] == prod]['UnitPrice'].mean()\n",
        "    j = 0\n",
        "    while prix > threshold[j]:\n",
        "        j+=1\n",
        "        if j == len(threshold): break\n",
        "    X.loc[i, label_col[j-1]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ag6HgAxdvaI"
      },
      "source": [
        "print(\"{:<8} {:<20} \\n\".format('gamme', 'nb. produits') + 20*'-')\n",
        "for i in range(len(threshold)):\n",
        "    if i == len(threshold)-1:\n",
        "        col = '.>{}'.format(threshold[i])\n",
        "    else:\n",
        "        col = '{}<.<{}'.format(threshold[i],threshold[i+1])    \n",
        "    print(\"{:<10}  {:<20}\".format(col, X.loc[:, col].sum()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc78zy2Ddzdu"
      },
      "source": [
        "matrix = X.as_matrix()\n",
        "for n_clusters in range(3,10):\n",
        "    kmeans = KMeans(init='k-means++', n_clusters = n_clusters, n_init=30)\n",
        "    kmeans.fit(matrix)\n",
        "    clusters = kmeans.predict(matrix)\n",
        "    silhouette_avg = silhouette_score(matrix, clusters)\n",
        "    print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMpQkyYpfAIs"
      },
      "source": [
        "n_clusters = 5\n",
        "silhouette_avg = -1\n",
        "while silhouette_avg < 0.145:\n",
        "    kmeans = KMeans(init='k-means++', n_clusters = n_clusters, n_init=30)\n",
        "    kmeans.fit(matrix)\n",
        "    clusters = kmeans.predict(matrix)\n",
        "    silhouette_avg = silhouette_score(matrix, clusters)\n",
        "    \n",
        "    #km = kmodes.KModes(n_clusters = n_clusters, init='Huang', n_init=2, verbose=0)\n",
        "    #clusters = km.fit_predict(matrix)\n",
        "    #silhouette_avg = silhouette_score(matrix, clusters)\n",
        "    print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hykxhp-SfD9N"
      },
      "source": [
        "pd.Series(clusters).value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHEPnwuCfKW3"
      },
      "source": [
        "def graph_component_silhouette(n_clusters, lim_x, mat_size, sample_silhouette_values, clusters):\n",
        "    plt.rcParams[\"patch.force_edgecolor\"] = True\n",
        "    plt.style.use('fivethirtyeight')\n",
        "    mpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\n",
        "    #____________________________\n",
        "    fig, ax1 = plt.subplots(1, 1)\n",
        "    fig.set_size_inches(8, 8)\n",
        "    ax1.set_xlim([lim_x[0], lim_x[1]])\n",
        "    ax1.set_ylim([0, mat_size + (n_clusters + 1) * 10])\n",
        "    y_lower = 10\n",
        "    for i in range(n_clusters):\n",
        "        #___________________________________________________________________________________\n",
        "        # Aggregate the silhouette scores for samples belonging to cluster i, and sort them\n",
        "        ith_cluster_silhouette_values = sample_silhouette_values[clusters == i]\n",
        "        ith_cluster_silhouette_values.sort()\n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "        color = cm.spectral(float(i) / n_clusters)        \n",
        "        ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values,\n",
        "                           facecolor=color, edgecolor=color, alpha=0.8)\n",
        "        #____________________________________________________________________\n",
        "        # Label the silhouette plots with their cluster numbers at the middle\n",
        "        ax1.text(-0.03, y_lower + 0.5 * size_cluster_i, str(i), color = 'red', fontweight = 'bold',\n",
        "                bbox=dict(facecolor='white', edgecolor='black', boxstyle='round, pad=0.3'))\n",
        "        #______________________________________\n",
        "        # Compute the new y_lower for next plot\n",
        "        y_lower = y_upper + 10  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRt54qhafQID"
      },
      "source": [
        "#____________________________________\n",
        "# define individual silouhette scores\n",
        "sample_silhouette_values = silhouette_samples(matrix, clusters)\n",
        "#__________________\n",
        "# and do the graph\n",
        "graph_component_silhouette(n_clusters, [-0.07, 0.33], len(X), sample_silhouette_values, clusters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hTLrD8ufQzj"
      },
      "source": [
        "liste = pd.DataFrame(liste_produits)\n",
        "liste_words = [word for (word, occurence) in list_products]\n",
        "\n",
        "occurence = [dict() for _ in range(n_clusters)]\n",
        "\n",
        "for i in range(n_clusters):\n",
        "    liste_cluster = liste.loc[clusters == i]\n",
        "    for word in liste_words:\n",
        "        if word in ['art', 'set', 'heart', 'pink', 'blue', 'tag']: continue\n",
        "        occurence[i][word] = sum(liste_cluster.loc[:, 0].str.contains(word.upper()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGDuCY1AfU3T"
      },
      "source": [
        "#________________________________________________________________________\n",
        "def random_color_func(word=None, font_size=None, position=None,\n",
        "                      orientation=None, font_path=None, random_state=None):\n",
        "    h = int(360.0 * tone / 255.0)\n",
        "    s = int(100.0 * 255.0 / 255.0)\n",
        "    l = int(100.0 * float(random_state.randint(70, 120)) / 255.0)\n",
        "    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n",
        "#________________________________________________________________________\n",
        "def make_wordcloud(liste, increment):\n",
        "    ax1 = fig.add_subplot(4,2,increment)\n",
        "    words = dict()\n",
        "    trunc_occurences = liste[0:150]\n",
        "    for s in trunc_occurences:\n",
        "        words[s[0]] = s[1]\n",
        "    #________________________________________________________\n",
        "    wordcloud = WordCloud(width=1000,height=400, background_color='lightgrey', \n",
        "                          max_words=1628,relative_scaling=1,\n",
        "                          color_func = random_color_func,\n",
        "                          normalize_plurals=False)\n",
        "    wordcloud.generate_from_frequencies(words)\n",
        "    ax1.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "    ax1.axis('off')\n",
        "    plt.title('cluster nº{}'.format(increment-1))\n",
        "#________________________________________________________________________\n",
        "fig = plt.figure(1, figsize=(14,14))\n",
        "color = [0, 160, 130, 95, 280, 40, 330, 110, 25]\n",
        "for i in range(n_clusters):\n",
        "    list_cluster_occurences = occurence[i]\n",
        "\n",
        "    tone = color[i] # define the color of the words\n",
        "    liste = []\n",
        "    for key, value in list_cluster_occurences.items():\n",
        "        liste.append([key, value])\n",
        "    liste.sort(key = lambda x:x[1], reverse = True)\n",
        "    make_wordcloud(liste, i+1)            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqjkOFbgfbNL"
      },
      "source": [
        "pca = PCA()\n",
        "pca.fit(matrix)\n",
        "pca_samples = pca.transform(matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWQwcs4efT3R"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(14, 5))\n",
        "sns.set(font_scale=1)\n",
        "plt.step(range(matrix.shape[1]), pca.explained_variance_ratio_.cumsum(), where='mid',\n",
        "         label='cumulative explained variance')\n",
        "sns.barplot(np.arange(1,matrix.shape[1]+1), pca.explained_variance_ratio_, alpha=0.5, color = 'g',\n",
        "            label='individual explained variance')\n",
        "plt.xlim(0, 100)\n",
        "\n",
        "ax.set_xticklabels([s if int(s.get_text())%2 == 0 else '' for s in ax.get_xticklabels()])\n",
        "\n",
        "plt.ylabel('Explained variance', fontsize = 14)\n",
        "plt.xlabel('Principal components', fontsize = 14)\n",
        "plt.legend(loc='upper left', fontsize = 13);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpcdNFRqh0eZ"
      },
      "source": [
        "corresp = dict()\n",
        "for key, val in zip (liste_produits, clusters):\n",
        "    corresp[key] = val \n",
        "#__________________________________________________________________________\n",
        "df_cleaned['categ_product'] = df_cleaned.loc[:, 'Description'].map(corresp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nrt6HXdmh7kT"
      },
      "source": [
        "for i in range(5):\n",
        "    col = 'categ_{}'.format(i)        \n",
        "    df_temp = df_cleaned[df_cleaned['categ_product'] == i]\n",
        "    price_temp = df_temp['UnitPrice'] * (df_temp['Quantity'] - df_temp['QuantityCanceled'])\n",
        "    price_temp = price_temp.apply(lambda x:x if x > 0 else 0)\n",
        "    df_cleaned.loc[:, col] = price_temp\n",
        "    df_cleaned[col].fillna(0, inplace = True)\n",
        "#__________________________________________________________________________________________________\n",
        "df_cleaned[['InvoiceNo', 'Description', 'categ_product', 'categ_0', 'categ_1', 'categ_2', 'categ_3','categ_4']][:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08lxxm2Bh8Ox"
      },
      "source": [
        "#___________________________________________\n",
        "# somme des achats / utilisateur & commande\n",
        "temp = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['TotalPrice'].sum()\n",
        "basket_price = temp.rename(columns = {'TotalPrice':'Basket Price'})\n",
        "#____________________________________________________________\n",
        "# pourcentage du prix de la commande / categorie de produit\n",
        "for i in range(5):\n",
        "    col = 'categ_{}'.format(i) \n",
        "    temp = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)[col].sum()\n",
        "    basket_price.loc[:, col] = temp \n",
        "#_____________________\n",
        "# date de la commande\n",
        "df_cleaned['InvoiceDate_int'] = df_cleaned['InvoiceDate'].astype('int64')\n",
        "temp = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['InvoiceDate_int'].mean()\n",
        "df_cleaned.drop('InvoiceDate_int', axis = 1, inplace = True)\n",
        "basket_price.loc[:, 'InvoiceDate'] = pd.to_datetime(temp['InvoiceDate_int'])\n",
        "#______________________________________\n",
        "# selection des entrées significatives:\n",
        "basket_price = basket_price[basket_price['Basket Price'] > 0]\n",
        "basket_price.sort_values('CustomerID', ascending = True)[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMdfQoCViHNp"
      },
      "source": [
        "print(basket_price['InvoiceDate'].min(), '->',  basket_price['InvoiceDate'].max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTpG57SQiJbp"
      },
      "source": [
        "set_entrainement = basket_price[basket_price['InvoiceDate'] < datetime.date(2011,10,1)]\n",
        "set_test         = basket_price[basket_price['InvoiceDate'] >= datetime.date(2011,10,1)]\n",
        "basket_price = set_entrainement.copy(deep = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0QaT_3uiKZU"
      },
      "source": [
        "transactions_per_user=basket_price.groupby(by=['CustomerID'])['Basket Price'].agg(['count','min','max','mean','sum'])\n",
        "for i in range(5):\n",
        "    col = 'categ_{}'.format(i)\n",
        "    transactions_per_user.loc[:,col] = basket_price.groupby(by=['CustomerID'])[col].sum() /\\\n",
        "                                            transactions_per_user['sum']*100\n",
        "\n",
        "transactions_per_user.reset_index(drop = False, inplace = True)\n",
        "basket_price.groupby(by=['CustomerID'])['categ_0'].sum()\n",
        "transactions_per_user.sort_values('CustomerID', ascending = True)[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oewcbcT-iNSw"
      },
      "source": [
        "last_date = basket_price['InvoiceDate'].max().date()\n",
        "\n",
        "first_registration = pd.DataFrame(basket_price.groupby(by=['CustomerID'])['InvoiceDate'].min())\n",
        "last_purchase      = pd.DataFrame(basket_price.groupby(by=['CustomerID'])['InvoiceDate'].max())\n",
        "\n",
        "test  = first_registration.applymap(lambda x:(last_date - x.date()).days)\n",
        "test2 = last_purchase.applymap(lambda x:(last_date - x.date()).days)\n",
        "\n",
        "transactions_per_user.loc[:, 'LastPurchase'] = test2.reset_index(drop = False)['InvoiceDate']\n",
        "transactions_per_user.loc[:, 'FirstPurchase'] = test.reset_index(drop = False)['InvoiceDate']\n",
        "\n",
        "transactions_per_user[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds43ZBs0iXWq"
      },
      "source": [
        "n1 = transactions_per_user[transactions_per_user['count'] == 1].shape[0]\n",
        "n2 = transactions_per_user.shape[0]\n",
        "print(\"nb. de clients avec achat unique: {:<2}/{:<5} ({:<2.2f}%)\".format(n1,n2,n1/n2*100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDENi7U3iYGe"
      },
      "source": [
        "list_cols = ['count','min','max','mean','categ_0','categ_1','categ_2','categ_3','categ_4']\n",
        "#_____________________________________________________________\n",
        "selected_customers = transactions_per_user.copy(deep = True)\n",
        "matrix = selected_customers[list_cols].as_matrix()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Emw48XUieHB"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(matrix)\n",
        "print('variables mean values: \\n' + 90*'-' + '\\n' , scaler.mean_)\n",
        "scaled_matrix = scaler.transform(matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR1AFN_Gier2"
      },
      "source": [
        "pca = PCA()\n",
        "pca.fit(scaled_matrix)\n",
        "pca_samples = pca.transform(scaled_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an4m2W-Zig_B"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(14, 5))\n",
        "sns.set(font_scale=1)\n",
        "plt.step(range(matrix.shape[1]), pca.explained_variance_ratio_.cumsum(), where='mid',\n",
        "         label='cumulative explained variance')\n",
        "sns.barplot(np.arange(1,matrix.shape[1]+1), pca.explained_variance_ratio_, alpha=0.5, color = 'g',\n",
        "            label='individual explained variance')\n",
        "plt.xlim(0, 10)\n",
        "\n",
        "ax.set_xticklabels([s if int(s.get_text())%2 == 0 else '' for s in ax.get_xticklabels()])\n",
        "\n",
        "plt.ylabel('Explained variance', fontsize = 14)\n",
        "plt.xlabel('Principal components', fontsize = 14)\n",
        "plt.legend(loc='best', fontsize = 13);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY-eMzexijiq"
      },
      "source": [
        "n_clusters = 11\n",
        "kmeans = KMeans(init='k-means++', n_clusters = n_clusters, n_init=100)\n",
        "kmeans.fit(scaled_matrix)\n",
        "clusters_clients = kmeans.predict(scaled_matrix)\n",
        "silhouette_avg = silhouette_score(scaled_matrix, clusters_clients)\n",
        "print('score de silhouette: {:<.3f}'.format(silhouette_avg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_iQxhTzitl3"
      },
      "source": [
        "pd.DataFrame(pd.Series(clusters_clients).value_counts(), columns = ['nb. de clients']).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzoNrnuyixr5"
      },
      "source": [
        "pca = PCA(n_components=6)\n",
        "matrix_3D = pca.fit_transform(scaled_matrix)\n",
        "mat = pd.DataFrame(matrix_3D)\n",
        "mat['cluster'] = pd.Series(clusters_clients)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3KEE2LKi0e3"
      },
      "source": [
        "import matplotlib.patches as mpatches\n",
        "\n",
        "sns.set_style(\"white\")\n",
        "sns.set_context(\"notebook\", font_scale=1, rc={\"lines.linewidth\": 2.5})\n",
        "\n",
        "LABEL_COLOR_MAP = {0:'r', 1:'tan', 2:'b', 3:'k', 4:'c', 5:'g', 6:'deeppink', 7:'skyblue', 8:'darkcyan', 9:'orange',\n",
        "                   10:'yellow', 11:'tomato', 12:'seagreen'}\n",
        "label_color = [LABEL_COLOR_MAP[l] for l in mat['cluster']]\n",
        "\n",
        "fig = plt.figure(figsize = (12,10))\n",
        "increment = 0\n",
        "for ix in range(6):\n",
        "    for iy in range(ix+1, 6):   \n",
        "        increment += 1\n",
        "        ax = fig.add_subplot(4,3,increment)\n",
        "        ax.scatter(mat[ix], mat[iy], c= label_color, alpha=0.5) \n",
        "        plt.ylabel('PCA {}'.format(iy+1), fontsize = 12)\n",
        "        plt.xlabel('PCA {}'.format(ix+1), fontsize = 12)\n",
        "        ax.yaxis.grid(color='lightgray', linestyle=':')\n",
        "        ax.xaxis.grid(color='lightgray', linestyle=':')\n",
        "        ax.spines['right'].set_visible(False)\n",
        "        ax.spines['top'].set_visible(False)\n",
        "        \n",
        "        if increment == 12: break\n",
        "    if increment == 12: break\n",
        "        \n",
        "#_______________________________________________\n",
        "# I set the legend: abreviation -> airline name\n",
        "comp_handler = []\n",
        "for i in range(n_clusters):\n",
        "    comp_handler.append(mpatches.Patch(color = LABEL_COLOR_MAP[i], label = i))\n",
        "\n",
        "plt.legend(handles=comp_handler, bbox_to_anchor=(1.1, 0.9), \n",
        "           title='Cluster', facecolor = 'lightgrey',\n",
        "           shadow = True, frameon = True, framealpha = 1,\n",
        "           fontsize = 13, bbox_transform = plt.gcf().transFigure)\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh5E4uATi7Yg"
      },
      "source": [
        "sample_silhouette_values = silhouette_samples(scaled_matrix, clusters_clients)\n",
        "#____________________________________\n",
        "# define individual silouhette scores\n",
        "sample_silhouette_values = silhouette_samples(scaled_matrix, clusters_clients)\n",
        "#__________________\n",
        "# and do the graph\n",
        "graph_component_silhouette(n_clusters, [-0.15, 0.55], len(scaled_matrix), sample_silhouette_values, clusters_clients)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ_eeY12i-9t"
      },
      "source": [
        "selected_customers.loc[:, 'cluster'] = clusters_clients"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm6IudUujC88"
      },
      "source": [
        "merged_df = pd.DataFrame()\n",
        "for i in range(n_clusters):\n",
        "    test = pd.DataFrame(selected_customers[selected_customers['cluster'] == i].mean())\n",
        "    test = test.T.set_index('cluster', drop = True)\n",
        "    test['size'] = selected_customers[selected_customers['cluster'] == i].shape[0]\n",
        "    merged_df = pd.concat([merged_df, test])\n",
        "#_____________________________________________________\n",
        "merged_df.drop('CustomerID', axis = 1, inplace = True)\n",
        "print('number of customers:', merged_df['size'].sum())\n",
        "\n",
        "merged_df = merged_df.sort_values('sum')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QcEVD1rjFQV"
      },
      "source": [
        "liste_index = []\n",
        "for i in range(5):\n",
        "    column = 'categ_{}'.format(i)\n",
        "    liste_index.append(merged_df[merged_df[column] > 45].index.values[0])\n",
        "#___________________________________\n",
        "liste_index_reordered = liste_index\n",
        "liste_index_reordered += [ s for s in merged_df.index if s not in liste_index]\n",
        "#___________________________________________________________\n",
        "merged_df = merged_df.reindex(index = liste_index_reordered)\n",
        "merged_df = merged_df.reset_index(drop = False)\n",
        "display(merged_df[['cluster', 'count', 'min', 'max', 'mean', 'sum', 'categ_0',\n",
        "                   'categ_1', 'categ_2', 'categ_3', 'categ_4', 'size']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMkinok1jJPe"
      },
      "source": [
        "def _scale_data(data, ranges):\n",
        "    (x1, x2) = ranges[0]\n",
        "    d = data[0]\n",
        "    return [(d - y1) / (y2 - y1) * (x2 - x1) + x1 for d, (y1, y2) in zip(data, ranges)]\n",
        "\n",
        "class RadarChart():\n",
        "    def __init__(self, fig, location, sizes, variables, ranges, n_ordinate_levels = 6):\n",
        "\n",
        "        angles = np.arange(0, 360, 360./len(variables))\n",
        "\n",
        "        ix, iy = location[:] ; size_x, size_y = sizes[:]\n",
        "        \n",
        "        axes = [fig.add_axes([ix, iy, size_x, size_y], polar = True, \n",
        "        label = \"axes{}\".format(i)) for i in range(len(variables))]\n",
        "\n",
        "        _, text = axes[0].set_thetagrids(angles, labels = variables)\n",
        "        \n",
        "        for txt, angle in zip(text, angles):\n",
        "            if angle > -1 and angle < 181:\n",
        "                txt.set_rotation(angle - 90)\n",
        "            else:\n",
        "                txt.set_rotation(angle - 270)\n",
        "                \n",
        "         for ax in axes[1:]:\n",
        "            ax.patch.set_visible(False)\n",
        "            ax.xaxis.set_visible(False)\n",
        "            ax.grid(\"off\")\n",
        "        \n",
        "        for i, ax in enumerate(axes):\n",
        "            grid = np.linspace(*ranges[i],num = n_ordinate_levels)\n",
        "            grid_label = [\"\"]+[\"{:.0f}\".format(x) for x in grid[1:-1]]\n",
        "            ax.set_rgrids(grid, labels = grid_label, angle = angles[i])\n",
        "            ax.set_ylim(*ranges[i])\n",
        "        \n",
        "        self.angle = np.deg2rad(np.r_[angles, angles[0]])\n",
        "        self.ranges = ranges\n",
        "        self.ax = axes[0]\n",
        "                \n",
        "    def plot(self, data, *args, **kw):\n",
        "        sdata = _scale_data(data, self.ranges)\n",
        "        self.ax.plot(self.angle, np.r_[sdata, sdata[0]], *args, **kw)\n",
        "\n",
        "    def fill(self, data, *args, **kw):\n",
        "        sdata = _scale_data(data, self.ranges)\n",
        "        self.ax.fill(self.angle, np.r_[sdata, sdata[0]], *args, **kw)\n",
        "        \n",
        "    def legend(self, *args, **kw):\n",
        "        self.ax.legend(*args, **kw)\n",
        "        \n",
        "    def title(self, title, *args, **kw):\n",
        "        self.ax.text(0.9, 1, title, transform = self.ax.transAxes, *args, **kw)\n",
        "        \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0kp-P6ajVF6"
      },
      "source": [
        "class Class_Fit(object):\n",
        "    def __init__(self, clf, params=None):\n",
        "        if params:            \n",
        "            self.clf = clf(**params)\n",
        "        else:\n",
        "            self.clf = clf()\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        self.clf.fit(x_train, y_train)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.clf.predict(x)\n",
        "    \n",
        "    def grid_search(self, parameters, Kfold):\n",
        "        self.grid = GridSearchCV(estimator = self.clf, param_grid = parameters, cv = Kfold)\n",
        "        \n",
        "    def grid_fit(self, X, Y):\n",
        "        self.grid.fit(X, Y)\n",
        "        \n",
        "    def grid_predict(self, X, Y):\n",
        "        self.predictions = self.grid.predict(X)\n",
        "        print(\"Precision: {:.2f} % \".format(100*metrics.accuracy_score(Y, self.predictions)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu8fXOa1jZBT"
      },
      "source": [
        "columns = ['mean', 'categ_0', 'categ_1', 'categ_2', 'categ_3', 'categ_4' ]\n",
        "X = selected_customers[columns]\n",
        "Y = selected_customers['cluster']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UZgJEXWjmar"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, train_size = 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAqs_XG_jojj"
      },
      "source": [
        "svc = Class_Fit(clf = svm.LinearSVC)\n",
        "svc.grid_search(parameters = [{'C':np.logspace(-2,2,10)}], Kfold = 5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EoMgw4zjsxw"
      },
      "source": [
        "svc.grid_fit(X = X_train, Y = Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFfedoUyjtZi"
      },
      "source": [
        "svc.grid_predict(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfbGxOuGjzFT"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "    #_________________________________________________\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=0)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    #_________________________________________________\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    #_________________________________________________\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1vcDUXNj2hd"
      },
      "source": [
        "class_names = [i for i in range(11)]\n",
        "cnf_matrix = confusion_matrix(Y_test, svc.predictions) \n",
        "np.set_printoptions(precision=2)\n",
        "plt.figure(figsize = (8,8))\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize = False, title='Confusion matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnzNX74Hj6tq"
      },
      "source": [
        "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
        "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 10)):\n",
        "    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVGnQhvdj90K"
      },
      "source": [
        "g = plot_learning_curve(svc.grid.best_estimator_,\n",
        "                        \"SVC learning curves\", X_train, Y_train, ylim = [1.01, 0.6],\n",
        "                        cv = 5,  train_sizes = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5,\n",
        "                                                0.6, 0.7, 0.8, 0.9, 1])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}